{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3108aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_bilancino_data()\n",
      "prepare(df)\n"
     ]
    }
   ],
   "source": [
    "# personally made imports\n",
    "import acquire_p\n",
    "\n",
    "# typical imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# modeling methods\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# working with dates\n",
    "from datetime import datetime\n",
    "\n",
    "# to evaluated performance using rmse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt \n",
    "\n",
    "# for tsa \n",
    "import statsmodels.api as sm\n",
    "\n",
    "# holt's linear trend model. \n",
    "from statsmodels.tsa.api import Holt\n",
    "\n",
    "#clean look\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31aa16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visual(df):\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for i, col in enumerate(df.columns):\n",
    "        plot_number = i + 1\n",
    "        l= len(df.columns)\n",
    "        plt.subplot(9,1,plot_number)\n",
    "        sns.lineplot(x = df.index, y = df[col])\n",
    "        plt.suptitle('---------------------20XX-------------------')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55fe6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake = acquire_p.get_bilancino_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59d4d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake = acquire_p.prepare(lake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acfb81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = lake[lake.index < '2006-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0f3a7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rainfall_S_Piero', 'Rainfall_Mangona', 'Rainfall_S_Agata',\n",
       "       'Rainfall_Cavallina', 'Rainfall_Le_Croci', 'Temperature_Le_Croci',\n",
       "       'Lake_Level', 'Flow_Rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e686dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = example.drop(columns = ['Rainfall_S_Piero', 'Rainfall_Mangona', 'Rainfall_S_Agata',\n",
    "       'Rainfall_Cavallina', 'Flow_Rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97477d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = example.resample('M').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22e029fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rainfall_S_Piero', 'Rainfall_Mangona', 'Rainfall_S_Agata',\n",
       "       'Rainfall_Cavallina', 'Rainfall_Le_Croci', 'Temperature_Le_Croci',\n",
       "       'Lake_Level', 'Flow_Rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "403a61f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearmanr(df):\n",
    "    spear = []\n",
    "    cat_col = ['Rainfall_S_Piero', 'Rainfall_Mangona', 'Rainfall_S_Agata',\n",
    "       'Rainfall_Cavallina', 'Rainfall_Le_Croci', 'Temperature_Le_Croci',\n",
    "       'Lake_Level', 'Flow_Rate']\n",
    "    for col in cat_col:\n",
    "        stats.spearmanr(df.Lake_Level, df[col])\n",
    "        spear.append(stats.spearmanr(df.Lake_Level, df[col]))\n",
    "    l = pd.DataFrame(spear, index = cat_col).round(4)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b14ed515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearmanr_a(df):\n",
    "    spear = []\n",
    "    cat_col = ['Rainfall_S_Piero', 'Rainfall_Mangona', 'Rainfall_S_Agata',\n",
    "       'Rainfall_Cavallina', 'Rainfall_Le_Croci', 'Temperature_Le_Croci',\n",
    "       'Lake_Level', 'Flow_Rate', 'avg_rain']\n",
    "    for col in cat_col:\n",
    "        stats.spearmanr(df.Lake_Level, df[col])\n",
    "        spear.append(stats.spearmanr(df.Lake_Level, df[col]))\n",
    "    l = pd.DataFrame(spear, index = cat_col).round(4)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179db46d",
   "metadata": {},
   "source": [
    "# 3 Month Shift\n",
    "3 months is appoximately 90 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef5cc492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift90(df):\n",
    "    col_list = ['Rainfall_S_Piero', 'Rainfall_Mangona', 'Rainfall_S_Agata', 'Rainfall_Cavallina', 'Rainfall_Le_Croci', 'Temperature_Le_Croci']\n",
    "    df[col_list] = df[col_list].shift(periods = 90, fill_value = 0)\n",
    "    df = df[df.index >= '2005-04-01']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e6fb2c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68cbd64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(target_var, yhat_df, validate):\n",
    "    '''\n",
    "    This function will take the actual values of the target_var from validate, \n",
    "    and the predicted values stored in yhat_df, \n",
    "    and compute the rmse, rounding to 0 decimal places. \n",
    "    it will return the rmse. \n",
    "    '''\n",
    "    rmse = round(sqrt(mean_squared_error(validate[target_var], yhat_df[target_var])), 4)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36f63e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_eval(target_var, train, yhat_df, validate):\n",
    "    '''\n",
    "    This function takes in the target var name (string), and returns a plot\n",
    "    of the values of train for that variable, validate, and the predicted values from yhat_df. \n",
    "    it will als lable the rmse. \n",
    "    '''\n",
    "    plt.figure(figsize = (12,4))\n",
    "    plt.plot(train[target_var], label='Train', linewidth=1)\n",
    "    plt.plot(validate[target_var], label='Validate', linewidth=1)\n",
    "    plt.plot(yhat_df[target_var])\n",
    "    plt.title(target_var)\n",
    "    rmse = evaluate(target_var, yhat_df, validate)\n",
    "    print(rmse)\n",
    "    plt.show()\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "150227e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to store the rmse so that we can compare\n",
    "def append_eval_df(model_type, target_var, yhat_df, validate):\n",
    "    '''\n",
    "    this function takes in as arguments the type of model run, and the name of the target variable. \n",
    "    It returns the eval_df with the rmse appended to it for that model and target_var. \n",
    "    '''\n",
    "    rmse = evaluate(target_var, yhat_df, validate)\n",
    "    d = {'model_type': [model_type],\n",
    "        'rmse': [rmse]}\n",
    "    d = pd.DataFrame(d)\n",
    "    return eval_df.append(d, ignore_index = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d522d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model_type, rmse]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.DataFrame(columns=['model_type', 'rmse'])\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd95df01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d53b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_transform(x_tr_data, y_tr_data, x_val_data, y_val_data):\n",
    "    # make the polynomial features to get a new set of features\n",
    "    pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "    # fit and transform X_train_scaled ONLY training gets fit, even for learning transformation!!!\n",
    "    x_tr_data_deg2 = pf.fit_transform(x_tr_data)\n",
    "\n",
    "    # transform X_validate_scaled & X_test_scaled\n",
    "    x_val_data_deg2 = pf.transform(x_val_data)\n",
    "\n",
    "    # create the model object\n",
    "    lm2 = LinearRegression(normalize=True)\n",
    "\n",
    "    # fit the model to our training data\n",
    "    lm2.fit(x_tr_data_deg2, y_tr_data)\n",
    "\n",
    "    # predict train\n",
    "    y_tr_data_deg2 = lm2.predict(x_tr_data_deg2)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_tr_data, y_tr_data_deg2)**(1/2)\n",
    "\n",
    "    # predict validate\n",
    "    y_val_data_deg2 = lm2.predict(x_val_data_deg2)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_validate = mean_squared_error(y_val_data, y_val_data_deg2)**(1/2)\n",
    "\n",
    "    print(\"RMSE for Polynomial Model, degrees=2\\nTraining/In-Sample: \", rmse_train.round(2), \n",
    "          \"\\nValidation/Out-of-Sample: \", rmse_validate.round(2))\n",
    "\n",
    "    return y_tr_data_deg2, y_val_data_deg2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28eae9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80809f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glm(x_tr_data, y_tr_data, x_val_data, y_val_data):\n",
    "\n",
    "    # create the model object\n",
    "    lm = TweedieRegressor(power=1, alpha=0)\n",
    "\n",
    "    # fit the model ONLY to our training data.  \n",
    "\n",
    "    lm.fit(x_tr_data, y_tr_data)\n",
    "\n",
    "    # predict train\n",
    "    y_tr_predict_glm = lm.predict(x_tr_data)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_tr_data, y_tr_predict_glm)**(1/2)\n",
    "\n",
    "    # predict validate\n",
    "    y_val_predict_glm = lm.predict(x_val_data)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_validate = mean_squared_error(y_val_data, y_val_predict_glm)**(1/2)\n",
    "\n",
    "    print(\"RMSE for OLS using GLM\\nTraining/In-Sample: \", rmse_train.round(2), \n",
    "          \"\\nValidation/Out-of-Sample: \", rmse_validate.round(2))\n",
    "    return y_tr_predict_glm, y_val_predict_glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3655bb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5004387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d87b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c3a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb400be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffc565e0",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd70e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(target_var, yhat_df, test):\n",
    "    '''\n",
    "    This function will take the actual values of the target_var from validate, \n",
    "    and the predicted values stored in yhat_df, \n",
    "    and compute the rmse, rounding to 0 decimal places. \n",
    "    it will return the rmse. \n",
    "    '''\n",
    "    rmse = round(sqrt(mean_squared_error(test[target_var], yhat_df[target_var])), 4)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee993adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_eval_test(target_var, train, validate, test, yhat_df):\n",
    "    '''\n",
    "    This function takes in the target var name (string), and returns a plot\n",
    "    of the values of train for that variable, validate, and the predicted values from yhat_df. \n",
    "    it will als lable the rmse. \n",
    "    '''\n",
    "    plt.figure(figsize = (12,4))\n",
    "    plt.plot(train[target_var], label='Train', linewidth=1)\n",
    "    plt.plot(validate[target_var], label='Validate', linewidth=1)\n",
    "    plt.plot(test[target_var], label='Test', linewidth=1)\n",
    "    plt.plot(yhat_df[target_var])\n",
    "    plt.title(target_var)\n",
    "    rmse = evaluate(target_var, yhat_df, test)\n",
    "    print(rmse)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa8ff37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f246ab12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c1f232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ebc1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6fda3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f68283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
